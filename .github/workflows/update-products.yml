name: Update products.json (Python + Selenium)

on:
  schedule:
    - cron: "0 2 * * *"   # daily at 02:00 UTC
  workflow_dispatch: {}    # allow manual runs

permissions:
  contents: write

jobs:
  scrape-and-commit:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Optional: show versions (helps debugging)
      - name: Show versions
        run: |
          python -c "import sys; print(sys.version)"
          python -c "import selenium; print('selenium', selenium.__version__)"

      # Run your exact scraper (expects category_links.json in repo root)
      - name: Run scraper
        env:
          # Add env vars here if your script needs any
          # e.g. BASE_URL: ${{ secrets.BASE_URL }}
          PYTHONUNBUFFERED: "1"
        run: python src/product_updater.py

      # Always upload the products file (and any debug folder your script might create)
      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: products-and-debug
          path: |
            docs/products.json
            debug/**
          if-no-files-found: warn

      # Commit and push only if products.json changed
      - name: Commit & push (if changed)
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add products.json || true
          git commit -m "chore: daily products.json refresh [skip ci]" || echo "No changes to commit"
          git push
